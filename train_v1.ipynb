{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import keras\n",
    "import os\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Reshape, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import concatenate\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.gridspec as gridspec\n",
    "from datetime import datetime\n",
    "\n",
    "from keras.layers import Conv2D, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'data/'\n",
    "save = 'save/'\n",
    "files = os.listdir(src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y_true, y_pred):     \n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    return np.mean(np.abs((y_true - y_pred)))\n",
    "\n",
    "count = 0\n",
    "now = datetime.now() \n",
    "name =str(now.year)+'_'+str(now.month)+'_'+str(now.day)+'_'+str(now.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test = pd.read_csv(src+'train.csv')\n",
    "x = csv_test.iloc[:,4:-1].values\n",
    "y = csv_test.iloc[:,0:4].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size=0.001, random_state=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "\n",
    "X_train_scale=sc.fit_transform(X_train)\n",
    "Y_train_scale=sc.fit_transform(Y_train)\n",
    "X_test_scale=sc.fit_transform(X_test)\n",
    "Y_test_scale=sc.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809190, 225)\n"
     ]
    }
   ],
   "source": [
    "np.shape(X_train_scale)\n",
    "X_train_scale_reshape = X_train_scale.reshape(809190, 225,1,1)\n",
    "X_train_scale_reshape = X_test_scale.reshape(810, 225,1,1)\n",
    "X_train_reshape = X_train.reshape(809190, 225,1,1)\n",
    "X_test_reshape = X_test.reshape(810, 225,1,1)\n",
    "print(np.shape(X_train_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab1_ysy/anaconda3/envs/tf2.0/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(600, (7, 1), activation=\"relu\")`\n",
      "  \"\"\"\n",
      "/home/lab1_ysy/anaconda3/envs/tf2.0/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(300, (4, 1), activation=\"relu\")`\n",
      "  import sys\n",
      "/home/lab1_ysy/anaconda3/envs/tf2.0/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(100, (2, 1), activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_5 (ZeroPaddin (None, 227, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 221, 1, 600)       4800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 215, 1, 600)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 212, 1, 300)       720300    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 209, 1, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 208, 1, 100)       60100     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 20800)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                1331264   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 2,116,724\n",
      "Trainable params: 2,116,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 801098 samples, validate on 8092 samples\n",
      "Epoch 1/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0608 - mae: 0.2022 - accuracy: 0.4291 - val_loss: 0.0446 - val_mae: 0.1695 - val_accuracy: 0.5509\n",
      "Epoch 2/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0399 - mae: 0.1571 - accuracy: 0.5809 - val_loss: 0.0366 - val_mae: 0.1495 - val_accuracy: 0.5927\n",
      "Epoch 3/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0353 - mae: 0.1454 - accuracy: 0.6119 - val_loss: 0.0339 - val_mae: 0.1420 - val_accuracy: 0.6064\n",
      "Epoch 4/100\n",
      "801098/801098 [==============================] - 161s 201us/step - loss: 0.0328 - mae: 0.1392 - accuracy: 0.6293 - val_loss: 0.0327 - val_mae: 0.1387 - val_accuracy: 0.6278\n",
      "Epoch 5/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0312 - mae: 0.1347 - accuracy: 0.6422 - val_loss: 0.0315 - val_mae: 0.1356 - val_accuracy: 0.6272\n",
      "Epoch 6/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0299 - mae: 0.1312 - accuracy: 0.6525 - val_loss: 0.0298 - val_mae: 0.1323 - val_accuracy: 0.6515\n",
      "Epoch 7/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0288 - mae: 0.1281 - accuracy: 0.6618 - val_loss: 0.0285 - val_mae: 0.1280 - val_accuracy: 0.6777\n",
      "Epoch 8/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0279 - mae: 0.1254 - accuracy: 0.6707 - val_loss: 0.0271 - val_mae: 0.1235 - val_accuracy: 0.6686\n",
      "Epoch 9/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0270 - mae: 0.1230 - accuracy: 0.6779 - val_loss: 0.0264 - val_mae: 0.1218 - val_accuracy: 0.6809\n",
      "Epoch 10/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0261 - mae: 0.1206 - accuracy: 0.6842 - val_loss: 0.0255 - val_mae: 0.1189 - val_accuracy: 0.6860\n",
      "Epoch 11/100\n",
      "801098/801098 [==============================] - 161s 201us/step - loss: 0.0253 - mae: 0.1185 - accuracy: 0.6895 - val_loss: 0.0248 - val_mae: 0.1172 - val_accuracy: 0.6927\n",
      "Epoch 12/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0246 - mae: 0.1166 - accuracy: 0.6947 - val_loss: 0.0244 - val_mae: 0.1155 - val_accuracy: 0.7034\n",
      "Epoch 13/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0239 - mae: 0.1149 - accuracy: 0.6991 - val_loss: 0.0247 - val_mae: 0.1179 - val_accuracy: 0.6797\n",
      "Epoch 14/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0233 - mae: 0.1132 - accuracy: 0.7034 - val_loss: 0.0234 - val_mae: 0.1130 - val_accuracy: 0.7108\n",
      "Epoch 15/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0227 - mae: 0.1118 - accuracy: 0.7065 - val_loss: 0.0228 - val_mae: 0.1118 - val_accuracy: 0.7069\n",
      "Epoch 16/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0222 - mae: 0.1103 - accuracy: 0.7095 - val_loss: 0.0222 - val_mae: 0.1105 - val_accuracy: 0.7002\n",
      "Epoch 17/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0218 - mae: 0.1092 - accuracy: 0.7131 - val_loss: 0.0225 - val_mae: 0.1111 - val_accuracy: 0.7079\n",
      "Epoch 18/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0214 - mae: 0.1083 - accuracy: 0.7145 - val_loss: 0.0214 - val_mae: 0.1087 - val_accuracy: 0.7219\n",
      "Epoch 19/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0210 - mae: 0.1071 - accuracy: 0.7174 - val_loss: 0.0224 - val_mae: 0.1101 - val_accuracy: 0.7101\n",
      "Epoch 20/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0207 - mae: 0.1064 - accuracy: 0.7188 - val_loss: 0.0211 - val_mae: 0.1067 - val_accuracy: 0.7247\n",
      "Epoch 21/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0204 - mae: 0.1055 - accuracy: 0.7207 - val_loss: 0.0210 - val_mae: 0.1079 - val_accuracy: 0.7021\n",
      "Epoch 22/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0201 - mae: 0.1048 - accuracy: 0.7222 - val_loss: 0.0205 - val_mae: 0.1061 - val_accuracy: 0.7200\n",
      "Epoch 23/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0199 - mae: 0.1041 - accuracy: 0.7242 - val_loss: 0.0200 - val_mae: 0.1053 - val_accuracy: 0.7299\n",
      "Epoch 24/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0196 - mae: 0.1033 - accuracy: 0.7263 - val_loss: 0.0199 - val_mae: 0.1045 - val_accuracy: 0.7301\n",
      "Epoch 25/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0194 - mae: 0.1027 - accuracy: 0.7270 - val_loss: 0.0194 - val_mae: 0.1025 - val_accuracy: 0.7308\n",
      "Epoch 26/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0192 - mae: 0.1023 - accuracy: 0.7289 - val_loss: 0.0195 - val_mae: 0.1031 - val_accuracy: 0.7156\n",
      "Epoch 27/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0190 - mae: 0.1016 - accuracy: 0.7305 - val_loss: 0.0193 - val_mae: 0.1023 - val_accuracy: 0.7205\n",
      "Epoch 28/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0188 - mae: 0.1012 - accuracy: 0.7315 - val_loss: 0.0194 - val_mae: 0.1035 - val_accuracy: 0.7226\n",
      "Epoch 29/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0186 - mae: 0.1006 - accuracy: 0.7324 - val_loss: 0.0191 - val_mae: 0.1016 - val_accuracy: 0.7363\n",
      "Epoch 30/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0184 - mae: 0.1001 - accuracy: 0.7343 - val_loss: 0.0190 - val_mae: 0.1019 - val_accuracy: 0.7331\n",
      "Epoch 31/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0183 - mae: 0.0998 - accuracy: 0.7351 - val_loss: 0.0184 - val_mae: 0.1000 - val_accuracy: 0.7327\n",
      "Epoch 32/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0181 - mae: 0.0992 - accuracy: 0.7362 - val_loss: 0.0189 - val_mae: 0.1015 - val_accuracy: 0.7344\n",
      "Epoch 33/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0180 - mae: 0.0989 - accuracy: 0.7377 - val_loss: 0.0182 - val_mae: 0.0996 - val_accuracy: 0.7379\n",
      "Epoch 34/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0178 - mae: 0.0984 - accuracy: 0.7381 - val_loss: 0.0184 - val_mae: 0.1006 - val_accuracy: 0.7352\n",
      "Epoch 35/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0177 - mae: 0.0980 - accuracy: 0.7399 - val_loss: 0.0189 - val_mae: 0.1012 - val_accuracy: 0.7326\n",
      "Epoch 36/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0176 - mae: 0.0977 - accuracy: 0.7402 - val_loss: 0.0186 - val_mae: 0.1006 - val_accuracy: 0.7360\n",
      "Epoch 37/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0174 - mae: 0.0972 - accuracy: 0.7418 - val_loss: 0.0180 - val_mae: 0.0985 - val_accuracy: 0.7352\n",
      "Epoch 38/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0173 - mae: 0.0968 - accuracy: 0.7428 - val_loss: 0.0187 - val_mae: 0.1022 - val_accuracy: 0.7302\n",
      "Epoch 39/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0171 - mae: 0.0965 - accuracy: 0.7439 - val_loss: 0.0172 - val_mae: 0.0964 - val_accuracy: 0.7436\n",
      "Epoch 40/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0170 - mae: 0.0961 - accuracy: 0.7451 - val_loss: 0.0174 - val_mae: 0.0973 - val_accuracy: 0.7412\n",
      "Epoch 41/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0169 - mae: 0.0958 - accuracy: 0.7453 - val_loss: 0.0173 - val_mae: 0.0972 - val_accuracy: 0.7506\n",
      "Epoch 42/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0168 - mae: 0.0955 - accuracy: 0.7464 - val_loss: 0.0179 - val_mae: 0.0992 - val_accuracy: 0.7304\n",
      "Epoch 43/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0167 - mae: 0.0952 - accuracy: 0.7468 - val_loss: 0.0172 - val_mae: 0.0967 - val_accuracy: 0.7359\n",
      "Epoch 44/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0166 - mae: 0.0949 - accuracy: 0.7479 - val_loss: 0.0172 - val_mae: 0.0974 - val_accuracy: 0.7473\n",
      "Epoch 45/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0165 - mae: 0.0948 - accuracy: 0.7478 - val_loss: 0.0166 - val_mae: 0.0947 - val_accuracy: 0.7554\n",
      "Epoch 46/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0163 - mae: 0.0941 - accuracy: 0.7500 - val_loss: 0.0167 - val_mae: 0.0951 - val_accuracy: 0.7459\n",
      "Epoch 47/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0163 - mae: 0.0941 - accuracy: 0.7502 - val_loss: 0.0165 - val_mae: 0.0944 - val_accuracy: 0.7568\n",
      "Epoch 48/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0162 - mae: 0.0938 - accuracy: 0.7509 - val_loss: 0.0164 - val_mae: 0.0943 - val_accuracy: 0.7507\n",
      "Epoch 49/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0161 - mae: 0.0935 - accuracy: 0.7514 - val_loss: 0.0162 - val_mae: 0.0935 - val_accuracy: 0.7535\n",
      "Epoch 50/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0159 - mae: 0.0930 - accuracy: 0.7531 - val_loss: 0.0166 - val_mae: 0.0946 - val_accuracy: 0.7556\n",
      "Epoch 51/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0159 - mae: 0.0929 - accuracy: 0.7531 - val_loss: 0.0160 - val_mae: 0.0935 - val_accuracy: 0.7558\n",
      "Epoch 52/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0158 - mae: 0.0926 - accuracy: 0.7534 - val_loss: 0.0157 - val_mae: 0.0927 - val_accuracy: 0.7590\n",
      "Epoch 53/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0157 - mae: 0.0923 - accuracy: 0.7543 - val_loss: 0.0164 - val_mae: 0.0944 - val_accuracy: 0.7441\n",
      "Epoch 54/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0157 - mae: 0.0923 - accuracy: 0.7545 - val_loss: 0.0160 - val_mae: 0.0935 - val_accuracy: 0.7502\n",
      "Epoch 55/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0155 - mae: 0.0917 - accuracy: 0.7562 - val_loss: 0.0158 - val_mae: 0.0924 - val_accuracy: 0.7544\n",
      "Epoch 56/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0154 - mae: 0.0915 - accuracy: 0.7565 - val_loss: 0.0155 - val_mae: 0.0921 - val_accuracy: 0.7640\n",
      "Epoch 57/100\n",
      "801098/801098 [==============================] - 159s 199us/step - loss: 0.0154 - mae: 0.0916 - accuracy: 0.7563 - val_loss: 0.0156 - val_mae: 0.0924 - val_accuracy: 0.7494\n",
      "Epoch 58/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0152 - mae: 0.0910 - accuracy: 0.7583 - val_loss: 0.0160 - val_mae: 0.0939 - val_accuracy: 0.7595\n",
      "Epoch 59/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0153 - mae: 0.0911 - accuracy: 0.7580 - val_loss: 0.0156 - val_mae: 0.0921 - val_accuracy: 0.7615\n",
      "Epoch 60/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0151 - mae: 0.0906 - accuracy: 0.7593 - val_loss: 0.0169 - val_mae: 0.0958 - val_accuracy: 0.7520\n",
      "Epoch 61/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0151 - mae: 0.0906 - accuracy: 0.7590 - val_loss: 0.0150 - val_mae: 0.0899 - val_accuracy: 0.7619\n",
      "Epoch 62/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0150 - mae: 0.0902 - accuracy: 0.7597 - val_loss: 0.0150 - val_mae: 0.0900 - val_accuracy: 0.7578\n",
      "Epoch 63/100\n",
      "801098/801098 [==============================] - 159s 199us/step - loss: 0.0149 - mae: 0.0899 - accuracy: 0.7606 - val_loss: 0.0156 - val_mae: 0.0921 - val_accuracy: 0.7570\n",
      "Epoch 64/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0149 - mae: 0.0899 - accuracy: 0.7610 - val_loss: 0.0167 - val_mae: 0.0958 - val_accuracy: 0.7410\n",
      "Epoch 65/100\n",
      "801098/801098 [==============================] - 159s 199us/step - loss: 0.0147 - mae: 0.0895 - accuracy: 0.7619 - val_loss: 0.0148 - val_mae: 0.0898 - val_accuracy: 0.7604\n",
      "Epoch 66/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0146 - mae: 0.0892 - accuracy: 0.7626 - val_loss: 0.0153 - val_mae: 0.0911 - val_accuracy: 0.7525\n",
      "Epoch 67/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0147 - mae: 0.0894 - accuracy: 0.7621 - val_loss: 0.0152 - val_mae: 0.0913 - val_accuracy: 0.7599\n",
      "Epoch 68/100\n",
      "801098/801098 [==============================] - 160s 199us/step - loss: 0.0145 - mae: 0.0889 - accuracy: 0.7630 - val_loss: 0.0151 - val_mae: 0.0908 - val_accuracy: 0.7619\n",
      "Epoch 69/100\n",
      "801098/801098 [==============================] - 160s 200us/step - loss: 0.0145 - mae: 0.0889 - accuracy: 0.7634 - val_loss: 0.0148 - val_mae: 0.0898 - val_accuracy: 0.7648\n",
      "Epoch 70/100\n",
      "365600/801098 [============>.................] - ETA: 1:26 - loss: 0.0143 - mae: 0.0883 - accuracy: 0.7650"
     ]
    }
   ],
   "source": [
    "def CNN(weights_path=None):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,0),input_shape=(225,1,1)))\n",
    "    model.add(Conv2D(600, 7, 1, activation='relu'))\n",
    "    model.add(MaxPooling2D((7,1), strides=(1,2))) \n",
    "    model.add(Conv2D(300, 4, 1, activation='relu'))\n",
    "    model.add(MaxPooling2D((4,1), strides=(1,2))) \n",
    "    model.add(Conv2D(100, 2, 1, activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(4, activation='linear'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model=CNN()\n",
    "model.summary()\n",
    "#plot_model(model, to_file=save+str(count)+'_Architecture_'+name+'.png', show_shapes=True)\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam , loss='mse', metrics=['mae','accuracy'])\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "hist = model.fit(X_train_reshape, Y_train_scale, batch_size=800, epochs=100,validation_split=0.01,callbacks=[early_stopping],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /home/lab1_ysy/anaconda3/envs/tf2.0/lib/python3.6/site-packages (1.4.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /home/lab1_ysy/anaconda3/envs/tf2.0/lib/python3.6/site-packages (from pydot) (2.4.6)\r\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_reshape, Y_test_scale, verbose=0)\n",
    "np.savetxt(save+str(count)+'_Score_'+name+'.txt', score)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(score)\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], label='val_loss')\n",
    "loss_ax.plot(hist.history['mean_absolute_error'], label='train acc')\n",
    "loss_ax.plot(hist.history['val_mean_absolute_error'], label='val acc')\n",
    "plt.savefig(save+str(count)+'_Train_curve_'+name+'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_test = abs(model.predict(X_test_reshape,batch_size=32))\n",
    "Y_hat_test_inverse = sc.inverse_transform(Y_hat_test)\n",
    "Y_test_inverse = sc.inverse_transform(Y_test_scale)\n",
    "\n",
    "record_pred = []\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "  Y_hat= list(map(int, Y_hat_test_inverse[i]))\n",
    "  print(i,'real:',Y_test_inverse[i],'pred:',Y_hat,' ',sep='\\n')\n",
    "  Y_append= np.append(Y_test_inverse[i],Y_hat)\n",
    "  record_pred.append(Y_append)  \n",
    "\n",
    "np.savetxt(save+str(count)+'_Record pred_'+name+'.csv', record_pred,delimiter=',')\n",
    "model.save_weights(save+str(count)+\"_Weight_\"+name+\".h5\")\n",
    "\n",
    "final = MAE()\n",
    "print('final mean_absolute_error:',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "from keras.models import model_from_json \n",
    "json_file = open(\"model.json\", \"r\") \n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close() \n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "loaded_model.load_weights(\"model.h5\") \n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['mae'])\n",
    "\n",
    "# model evaluation\n",
    "score = loaded_model.evaluate(X_test_scale,Y_test_scale,verbose=0)\n",
    "\n",
    "print(\"%s : %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
