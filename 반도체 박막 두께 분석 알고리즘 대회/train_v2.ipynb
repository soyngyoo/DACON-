{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import keras\n",
    "import os\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Reshape, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import concatenate,BatchNormalization,Activation\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import scipy.io\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.gridspec as gridspec\n",
    "from datetime import datetime\n",
    "\n",
    "from keras.layers import Conv2D, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'data/'\n",
    "save = 'save/'\n",
    "files = os.listdir(src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y_true, y_pred):     \n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    return np.mean(np.abs((y_true - y_pred)))\n",
    "\n",
    "count = 0\n",
    "now = datetime.now() \n",
    "name =str(now.year)+'_'+str(now.month)+'_'+str(now.day)+'_'+str(now.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test = pd.read_csv(src+'train.csv')\n",
    "x = csv_test.iloc[:,4:-1].values\n",
    "y = csv_test.iloc[:,0:4].values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size=0.001, random_state=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = MinMaxScaler()\n",
    "\n",
    "X_train_scale=sc.fit_transform(X_train)\n",
    "Y_train_scale=sc.fit_transform(Y_train)\n",
    "X_test_scale=sc.fit_transform(X_test)\n",
    "Y_test_scale=sc.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809190, 225)\n"
     ]
    }
   ],
   "source": [
    "np.shape(X_train_scale)\n",
    "X_train_scale_reshape = X_train_scale.reshape(809190, 225,1,1)\n",
    "X_train_scale_reshape = X_test_scale.reshape(810, 225,1,1)\n",
    "X_train_reshape = X_train.reshape(809190, 225,1,1)\n",
    "X_test_reshape = X_test.reshape(810, 225,1,1)\n",
    "print(np.shape(X_train_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 300)               67800     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 600)               180600    \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 600)               360600    \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1000)              601000    \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 4)                 4004      \n",
      "=================================================================\n",
      "Total params: 3,306,304\n",
      "Trainable params: 3,306,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 801098 samples, validate on 8092 samples\n",
      "Epoch 1/100\n",
      "801098/801098 [==============================] - 41s 51us/step - loss: 0.0272 - mae: 0.1138 - accuracy: 0.6715 - val_loss: 0.0119 - val_mae: 0.0686 - val_accuracy: 0.8008\n",
      "Epoch 2/100\n",
      "801098/801098 [==============================] - 41s 51us/step - loss: 0.0087 - mae: 0.0564 - accuracy: 0.8336 - val_loss: 0.0062 - val_mae: 0.0459 - val_accuracy: 0.8641\n",
      "Epoch 3/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0060 - mae: 0.0456 - accuracy: 0.8650 - val_loss: 0.0051 - val_mae: 0.0411 - val_accuracy: 0.8764\n",
      "Epoch 4/100\n",
      "801098/801098 [==============================] - 39s 49us/step - loss: 0.0047 - mae: 0.0401 - accuracy: 0.8799 - val_loss: 0.0038 - val_mae: 0.0358 - val_accuracy: 0.8931\n",
      "Epoch 5/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0041 - mae: 0.0372 - accuracy: 0.8889 - val_loss: 0.0035 - val_mae: 0.0359 - val_accuracy: 0.8929\n",
      "Epoch 6/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0036 - mae: 0.0354 - accuracy: 0.8941 - val_loss: 0.0041 - val_mae: 0.0374 - val_accuracy: 0.8841\n",
      "Epoch 7/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0032 - mae: 0.0334 - accuracy: 0.8996 - val_loss: 0.0032 - val_mae: 0.0323 - val_accuracy: 0.8961\n",
      "Epoch 8/100\n",
      "801098/801098 [==============================] - 39s 49us/step - loss: 0.0030 - mae: 0.0322 - accuracy: 0.9035 - val_loss: 0.0029 - val_mae: 0.0313 - val_accuracy: 0.9045\n",
      "Epoch 9/100\n",
      "801098/801098 [==============================] - 41s 51us/step - loss: 0.0027 - mae: 0.0310 - accuracy: 0.9069 - val_loss: 0.0021 - val_mae: 0.0288 - val_accuracy: 0.9207\n",
      "Epoch 10/100\n",
      "801098/801098 [==============================] - 41s 51us/step - loss: 0.0026 - mae: 0.0303 - accuracy: 0.9090 - val_loss: 0.0025 - val_mae: 0.0293 - val_accuracy: 0.9078\n",
      "Epoch 11/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0025 - mae: 0.0297 - accuracy: 0.9109 - val_loss: 0.0025 - val_mae: 0.0296 - val_accuracy: 0.9153\n",
      "Epoch 12/100\n",
      "801098/801098 [==============================] - 41s 51us/step - loss: 0.0023 - mae: 0.0290 - accuracy: 0.9129 - val_loss: 0.0027 - val_mae: 0.0318 - val_accuracy: 0.9097\n",
      "Epoch 13/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0022 - mae: 0.0284 - accuracy: 0.9154 - val_loss: 0.0021 - val_mae: 0.0279 - val_accuracy: 0.9197\n",
      "Epoch 14/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0021 - mae: 0.0279 - accuracy: 0.9161 - val_loss: 0.0022 - val_mae: 0.0301 - val_accuracy: 0.9183\n",
      "Epoch 15/100\n",
      "801098/801098 [==============================] - 39s 49us/step - loss: 0.0021 - mae: 0.0278 - accuracy: 0.9169 - val_loss: 0.0019 - val_mae: 0.0264 - val_accuracy: 0.9219\n",
      "Epoch 16/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0020 - mae: 0.0271 - accuracy: 0.9192 - val_loss: 0.0031 - val_mae: 0.0329 - val_accuracy: 0.9097\n",
      "Epoch 17/100\n",
      "801098/801098 [==============================] - 39s 49us/step - loss: 0.0019 - mae: 0.0269 - accuracy: 0.9195 - val_loss: 0.0017 - val_mae: 0.0254 - val_accuracy: 0.9226\n",
      "Epoch 18/100\n",
      "801098/801098 [==============================] - 39s 49us/step - loss: 0.0019 - mae: 0.0268 - accuracy: 0.9198 - val_loss: 0.0015 - val_mae: 0.0242 - val_accuracy: 0.9319\n",
      "Epoch 19/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0018 - mae: 0.0265 - accuracy: 0.9213 - val_loss: 0.0030 - val_mae: 0.0322 - val_accuracy: 0.9131\n",
      "Epoch 20/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0018 - mae: 0.0259 - accuracy: 0.9225 - val_loss: 0.0015 - val_mae: 0.0252 - val_accuracy: 0.9241\n",
      "Epoch 21/100\n",
      "801098/801098 [==============================] - 41s 51us/step - loss: 0.0017 - mae: 0.0260 - accuracy: 0.9220 - val_loss: 0.0018 - val_mae: 0.0260 - val_accuracy: 0.9283\n",
      "Epoch 22/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0017 - mae: 0.0257 - accuracy: 0.9236 - val_loss: 0.0019 - val_mae: 0.0261 - val_accuracy: 0.9228\n",
      "Epoch 23/100\n",
      "801098/801098 [==============================] - 41s 51us/step - loss: 0.0017 - mae: 0.0257 - accuracy: 0.9234 - val_loss: 0.0014 - val_mae: 0.0234 - val_accuracy: 0.9314\n",
      "Epoch 24/100\n",
      "801098/801098 [==============================] - 40s 49us/step - loss: 0.0016 - mae: 0.0253 - accuracy: 0.9243 - val_loss: 0.0017 - val_mae: 0.0265 - val_accuracy: 0.9167\n",
      "Epoch 25/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0017 - mae: 0.0255 - accuracy: 0.9238 - val_loss: 0.0013 - val_mae: 0.0236 - val_accuracy: 0.9325\n",
      "Epoch 26/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0016 - mae: 0.0250 - accuracy: 0.9250 - val_loss: 0.0025 - val_mae: 0.0281 - val_accuracy: 0.9163\n",
      "Epoch 27/100\n",
      "801098/801098 [==============================] - 40s 49us/step - loss: 0.0016 - mae: 0.0250 - accuracy: 0.9255 - val_loss: 0.0017 - val_mae: 0.0245 - val_accuracy: 0.9236\n",
      "Epoch 28/100\n",
      "801098/801098 [==============================] - 39s 49us/step - loss: 0.0016 - mae: 0.0248 - accuracy: 0.9261 - val_loss: 0.0019 - val_mae: 0.0258 - val_accuracy: 0.9288\n",
      "Epoch 29/100\n",
      "801098/801098 [==============================] - 40s 49us/step - loss: 0.0016 - mae: 0.0247 - accuracy: 0.9263 - val_loss: 0.0019 - val_mae: 0.0271 - val_accuracy: 0.9288\n",
      "Epoch 30/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0015 - mae: 0.0244 - accuracy: 0.9275 - val_loss: 0.0011 - val_mae: 0.0218 - val_accuracy: 0.9334\n",
      "Epoch 31/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0016 - mae: 0.0248 - accuracy: 0.9266 - val_loss: 0.0021 - val_mae: 0.0288 - val_accuracy: 0.9178\n",
      "Epoch 32/100\n",
      "801098/801098 [==============================] - 39s 49us/step - loss: 0.0015 - mae: 0.0244 - accuracy: 0.9274 - val_loss: 0.0024 - val_mae: 0.0301 - val_accuracy: 0.9158\n",
      "Epoch 33/100\n",
      "801098/801098 [==============================] - 40s 51us/step - loss: 0.0015 - mae: 0.0244 - accuracy: 0.9274 - val_loss: 0.0014 - val_mae: 0.0236 - val_accuracy: 0.9282\n",
      "Epoch 34/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0014 - mae: 0.0237 - accuracy: 0.9291 - val_loss: 0.0015 - val_mae: 0.0251 - val_accuracy: 0.9246\n",
      "Epoch 35/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0014 - mae: 0.0239 - accuracy: 0.9290 - val_loss: 0.0015 - val_mae: 0.0242 - val_accuracy: 0.9286\n",
      "Epoch 36/100\n",
      "801098/801098 [==============================] - 41s 51us/step - loss: 0.0014 - mae: 0.0239 - accuracy: 0.9285 - val_loss: 0.0019 - val_mae: 0.0272 - val_accuracy: 0.9152\n",
      "Epoch 37/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0014 - mae: 0.0237 - accuracy: 0.9293 - val_loss: 0.0019 - val_mae: 0.0266 - val_accuracy: 0.9262\n",
      "Epoch 38/100\n",
      "801098/801098 [==============================] - 40s 50us/step - loss: 0.0014 - mae: 0.0237 - accuracy: 0.9289 - val_loss: 0.0014 - val_mae: 0.0237 - val_accuracy: 0.9281\n",
      "Epoch 39/100\n",
      "801098/801098 [==============================] - 39s 49us/step - loss: 0.0014 - mae: 0.0237 - accuracy: 0.9292 - val_loss: 0.0017 - val_mae: 0.0252 - val_accuracy: 0.9205\n",
      "Epoch 40/100\n",
      "801098/801098 [==============================] - 39s 49us/step - loss: 0.0014 - mae: 0.0239 - accuracy: 0.9286 - val_loss: 0.0013 - val_mae: 0.0244 - val_accuracy: 0.9256\n"
     ]
    }
   ],
   "source": [
    "leaky_relu = tf.nn.leaky_relu\n",
    "\n",
    "def CNN(weights_path=None):\n",
    "\n",
    "    model = Sequential()\n",
    "    #model.add(ZeroPadding2D((1,0),input_shape=(225,1,1)))\n",
    "    model.add(Conv2D(112, 3, 1, activation='relu',input_shape=(225,1,1)))\n",
    "    model.add(Activation(leaky_relu))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,1), strides=(1,2)))\n",
    "    model.add(Conv2D(224, 3, 1,activation='relu'))\n",
    "    model.add(Activation(leaky_relu))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2,1), strides=(1,2)))\n",
    "    model.add(Conv2D(448, 4, 1,activation ='relu'))\n",
    "    model.add(Activation(leaky_relu))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(102, activation='relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(4, activation='linear'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def NN(weights_path=None):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, activation='relu',input_shape=(225,)))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(4, activation='linear'))\n",
    "\n",
    "    return model\n",
    "\n",
    "model=NN()\n",
    "model.summary()\n",
    "#pyplot_model(model, to_file=save+str(count)+'_Architecture_'+name+'.png', show_shapes=True)\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer= adam , loss='mse', metrics=['mae','accuracy'])\n",
    "early_stopping = EarlyStopping(patience=10)\n",
    "\n",
    "hist = model.fit(X_train, Y_train_scale, batch_size=128, epochs=100,validation_split=0.01,callbacks=[early_stopping],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mae', 'accuracy']\n",
      "[0.0012730151078560285, 0.0236677099019289, 0.9382715821266174]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAD8CAYAAAC2PJlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXxcZdn/8c81+2Tf0zZpm4SuKZQCbdkXQRGQVZFNEbSK/hR9kEVQngcQfUBAARWU/RFRKLuWUqkgIItsZe9CS/c2TZpmXyaz378/zklI0rSZZpt0cr1fr3nNzDlnzrnmpM03577PuY8YY1BKKaUGwpHsApRSSu29NESUUkoNmIaIUkqpAdMQUUopNWAaIkoppQZMQ0QppdSAaYgopdQYICIPiEitiCzfxXwRkd+JyFoR+UhEDkxkvRoiSik1NvwJOGE3808EptqPi4A/JrJSDRGllBoDjDGvAA27WeQ04M/G8iaQIyLj+1uva6gKHCoOh8P4/f5kl6GUUnuVQCBggPe6TbrHGHPPHqyiBNjS7f1We1r17j406kLE7/fT3t6e7DKUUmqvIiIdxpi5I71dbc5SSikFUAVM7Pa+1J62WxoiSimlABYB37DP0joEaDbG7LYpC0Zhc5ZSSqmhJyKPAMcABSKyFbgWcAMYY+4ClgAnAWuBAPDNhNY72oaCT09PN9onopRSe0ZEAsaY9JHerjZnKaWUGjANEaWUUgOmIaKUUmrAUiZEatpruOP9O9jUsinZpSil1JiRMiHSGGzk7o/uZm3j2mSXopRSY0bKhEiuLxeAxlBjkitRSqmxI2VCJNubDUBTqCnJlSil1NiRMiHid/nxu/w0BTVElFJqpKRMiADkeHO0OUsppUZQyoWINmcppdTISb0Q0eYspZQaMakVIj5tzlJKqZGUUiGS683V5iyllBpBKRUiOb4cWsOtROKRZJeilFJjQkqFSK7XuuCwOdSc5EqUUmpsSKkQyfHlAGjnulJKjZDUChGvFSLaua6UUiMjpUKkszlLO9eVUmpkpFSIdB2JBPVIRCmlRkJqhYjdJ6Id60opNTJSKkS8Ti9prjTtE1FKqRGSUiEC1n1F9OwspZQaGSkXIjqSr1JKjZyUDBE9ElFKqZGReiGigzAqpdSISShEROQEEVktImtF5Ko+5h8lIu+JSFREzuw17wIR+dR+XDBUhe9KrjdXz85SSqkR0m+IiIgTuBM4EagEzhWRyl6LbQYuBB7u9dk84FrgYGA+cK2I5A6+7F3L8ebQFmkjEtNBGJVSarglciQyH1hrjFlvjAkDC4HTui9gjNlojPkIiPf67BeB540xDcaYRuB54IQhqHuXcn161bpSSo2UREKkBNjS7f1We1oiEvqsiFwkIstEZFk0Gk1w1X3T8bOUUmrkjIqOdWPMPcaYucaYuS6Xa1Dr6joS0TO0lFJq2CUSIlXAxG7vS+1piRjMZwck25sN6JGIUkqNhERC5B1gqoiUi4gHOAdYlOD6lwLHi0iu3aF+vD1t2HSN5KtHIkopNez6DRFjTBS4GOuX/yrgMWPMChG5XkROBRCReSKyFfgqcLeIrLA/2wD8AiuI3gGut6cNm84+Ee1YV0qp4ZdQB4QxZgmwpNe0a7q9fgerqaqvzz4APDCIGveI2+kmw52hIaKUUiNgVHSsDzUdP0sppUZGSoaIjuSrlFI7S2D0kUki8pKIvC8iH4nISf2tMyVDRI9ElFKqpwRHH/lvrH7vA7BOovpDf+tN2RDRIxGllOqh39FHAANk2a+zgW39rXRwV/aNUjm+HO1YV0qNNS4RWdbt/T3GmHu6ve9rBJGDe63jOuCfIvJDIB34fL8bHVito1uuN5dANEAoFsLr9Ca7HKWUGglRY8zcQa7jXOBPxpjfiMihwEMisq8xpve4iF1SsznLZ18rok1aSinVKZERRBYAjwEYY94AfEDB7laakiHSddW6NmkppVSnREYf2QwcByAiM7FCZMfuVpqSIaIj+SqlVE+JjD4CXAZ8R0Q+BB4BLjTGmN2tNzX7RHQkX6WU2kkCo4+sBA7fk3Wm5JGIjuSrlFIjI6VDRPtElFJqeKVkiLgdbjI9mdqcpZRSwywlQwSsM7S0OUsppYZXyoZIjk+HPlFKqeGWsiGS683VPhGllBpmKRsiOpKvUkoNv5QOEW3OUkqp4ZW6IeLLIRgL0hHtSHYpSimVslI2RDrHz2oONSe5EqWUSl0pGyKdI/k2BrVfRCmlhkvKhkjnkYh2riul1PBJ2RDRe4oopdTwS90Q0eHglVJq2KVsiGR5shBEO9aVUmoYpWyIuBwusrxZ2rGulFLDKKEQEZETRGS1iKwVkav6mO8VkUft+W+JSJk93S0iD4rIxyKySkR+OrTl754OfaKUUsOr3xARESdwJ3AiUAmcKyKVvRZbADQaY6YAtwE32dO/CniNMfsBBwHf7QyYkaBDnyil1PBK5EhkPrDWGLPeGBMGFgKn9VrmNOBB+/UTwHEiIoAB0kXEBfiBMNAyJJUnQEfyVUqp4ZVIiJQAW7q932pP63MZ+2bwzUA+VqC0A9XAZuDXxpiG3hsQkYtEZJmILItGo3v8JXZF7ymilFLDa7g71ucDMWACUA5cJiIVvRcyxtxjjJlrjJnrcrmGbOOdgzAaY4ZsnUoppT6TSIhUARO7vS+1p/W5jN10lQ3UA+cBzxljIsaYWuB1YO5gi05Uji+HcDysgzAqpdQwSSRE3gGmiki5iHiAc4BFvZZZBFxgvz4TeNFYf/5vBo4FEJF04BDgk6EoPBGdQ5/oGVpKKTU8+g0Ru4/jYmApsAp4zBizQkSuF5FT7cXuB/JFZC1wKdB5GvCdQIaIrMAKo/8zxnw01F9iV/SqdaWUGl4JdUAYY5YAS3pNu6bb6yDW6by9P9fW1/SRkuuzj0T0DC2llBoWKXvFOuiRiFJKDbeUDhE9ElFKqeGV0iGS6cnEIQ7tWFdKqWGS0iHiEAfZnmwNEaWUGiYpHSJgXSuiI/kqpdTwSPkQ0ZF8lVJq+KR8iOhIvkopNXxSPkRyfbl6dpZSSg2TlA+RziMRHYRRKaWG3pgIkWg8SiAaSHYpSimVVP3dpdZe5iwRWSkiK0Tk4f7WOXTjro9SOT77qvVgI+nu9CRXo5RSydHtLrVfwLov1DsissgYs7LbMlOBnwKHG2MaRaSov/Wm/JGIjuSrlFJAYnep/Q5wpzGmEcC+hcdupXyIdD8SUUqpFObqvEOs/bio1/xE7lI7DZgmIq+LyJsickK/Gx1czaNHPBgkuHw53mnTcGZldU3XIxGl1BgRNcYM9qZ/LmAqcAzWDQhfEZH9jDG7/AWaMkciwZWr2PT18wkse7fHdD0SUUopILG71G4FFtl3o90ArMEKlV1KmRDxzZgODgfBlSt7TM90Z+IUpx6JKKXGukTuUvs3rKMQRKQAq3lr/e5WmjIh4khLw1NRvlOIiAjZXh2EUSk1tiV4l9qlQL2IrAReAq4wxtTvbr0p0ycC4KusJPDW2ztN1/GzlFIqobvUGqxbnF+a6DpT5kgErBCJbt9OtK6ux3QdyVcppYZHyoUIQHDVqh7T9UhEKaWGR2qGyIoVPabrkYhSSg2PlAoRZ0YGnsmTCa7o2bme682lOdSsgzAqpdQQS6kQAfDNqtzpDK0cbw5RE6Ut0pakqpRSKjWlXohUVhKpqiLW9FkfSOcFh3pfEaWUGlqpFyKzZgH0OBrJ8dpXresdDpVSakilXojMnAn0DBEdP0sppYZHQiHS341MRMQrIo/a898SkbJu82aLyBv2DU4+FhHf0JW/M2dODu6Skp5HIjp+llJKDYt+Q6TbjUxOBCqBc0WkstdiC4BGY8wU4DbgJvuzLuAvwPeMMbOwxmSJDFn1u+CrrOxxhpYeiSil1PBI5EgkkRuZnAY8aL9+AjhORAQ4HvjIGPMhgDGm3hgTG5rSd803axbhTZuItbYCkO5Ox+Vw6ZGIUkoNsURCJJEbmXQtYw/y1QzkY40AaURkqYi8JyI/GXzJ/fPN6nnluojoVetKKTUMhrtj3QUcAXzNfj5DRI7rvZCIXNR5N65oNDrojfbVua4j+Sql1NBLJEQSuZFJ1zJ2P0g2UI911PKKMabOGBPAGj3ywN4bMMbcY4yZa4yZ63INfmBhV0EBruLinv0ivlxtzlJKqSGWSIgkciOTRcAF9uszgRftIYWXAvuJSJodLkcDKxkBvlmzdrpWRI9ElFJqaPUbIgneyOR+IF9E1mKNQ3+V/dlG4FasIPoAeM8Y8+zQf42d+SorCa9fTzwQAHQkX6WUGg4JtR0lcCOTIPDVXXz2L1in+Y4oX2UlGEPwk9WkHXgAOT7rSCRu4jgk5a6xVEqppEjZ36Zdw5/Yw8LnenOJm7j2iyil1BBK2RBxFRXiLCjo6hfZv3B/AF7Y9EIyy1JKqZSSsiEiIvgqZ3aFyL4F+zIzbyYLVy/U+4oopdQQSdkQAatfJLR2LfFQCBHhnBnnsLZpLe/Vvpfs0pRSKiWkdojMmgWxGKHVqwE4sfxEMt2ZPPrJo0muTCmlUkNKh4i/857rdpOW3+XntCmn8fzm56nrqEtmaUoplRJSOkRcEybgzM7uceX6WdPPIhqP8vSnTyexMqWUSg0pHSIiYt1z3T7NF6A8u5yDxx/MY2seIxYf9gGFlVIqpaV0iIA9/Mmnn2LC4a5p50w/h5r2Gl7Z+koSK1NKqb1f6odIZSVEIoTWru2adszEYyjyF/Hoau1gV0qpwRgbIULPYeFdDhdnTjuT17e9zpaWLbv6qFJKqX6kfIi4J07EkZFBR7d+EYCvTPsKTnHy2JrHklSZUkrt/VI+RMThsO65vrLnCPRFaUUcO+lYnl77NMFoMEnVKaXU3i3lQwTsK9c/WY3pddfEs6efTXOomaUblyapMqWU2ruNjRCZVYkJhQitW99j+vxx8ynLKuOx1dqkpZRSAzE2QqSPznWgazytj+o+YkX9ir4+qpRSajfGRIh4ysqQtLSdQgTglH1Owe/y69GIUkoNwJgIEXE68c2Y0WeIZHmyOKn8JJasX0JzqDkJ1Sml1N5rTIQIWE1awVWrMLGdhzo5a/pZBGNBnln3TBIqU0qpkSEiJ4jIahFZKyJX7Wa5r4iIEZG5/a1zzIRI+iEHYwIBtv/v/+50U6rK/EpmF87mL6v+Qmu4NUkVKqXU8BERJ3AncCJQCZwrIpV9LJcJ/BfwViLrHTMhknHcceQt+BaNDz/Cjt/+dqf5lxx4CTXtNfzs1Z8RN/EkVKiUUsNqPrDWGLPeGBMGFgKn9bHcL4CbgIQuoBszISIiFF1+OTlfPZP6u+6m/oH/6zF/3rh5XDHvCl7e+jJ/+OAPSapSKaUGzCUiy7o9Luo1vwToPs7TVntaFxE5EJhojHk24Y0OuNy9kIgw7rrriLW2UXvzzTizs8j5yle65p834zw+afiEuz+6mxl5M/j85M8nsVqllNojUWNMv30YuyIiDuBW4MI9+dyYORLpJE4nE26+ifTDD6f6f66hZek/P5snwv8c8j/MLpjNz177GWsa1ySxUqWUGlJVwMRu70vtaZ0ygX2Bl0VkI3AIsKi/znXp3cmcbOnp6aa9vX3YtxMPBNj8rQUEV6yg9K4/knH44V3zagO1nLP4HLxOLwtPXki2N3vY61FKqcEQkYAxJn03813AGuA4rPB4BzjPGNPnldYi8jJwuTFm2e62O+aORDo50tKYePddeMrL2frDH9HxwQdd84rSirjtc7exPbCdy/99OdF4dDdrUkqp0c8YEwUuBpYCq4DHjDErROR6ETl1oOtN6EhERE4Afgs4gfuMMb/qNd8L/Bk4CKgHzjbGbOw2fxKwErjOGPPr3W1rpI5EOkV37GDj175OrLmZyX/+M77p07rmPf3p01zzn2v4RuU3uGLeFSNWk1JK7an+jkSGS79HIgmeW7wAaDTGTAFuwzo9rLtbgX8Mvtyh5yosZNID9+Pwetny7W8TqanpmnfG1DM4d8a5/Hnln/VCRKWU6kMizVmJnFt8GvCg/foJ4DgREQAROR3YAIzaEQ49paVMvPde4u3tbPn+94kHAl3zrph3BfPGzeO6/1zHxzs+TmKVSik1+iQSIv2eW9x9GbvdrRnIF5EM4Erg54MvdXj5pk9jwq2/IfTJaqp+8hNM3Lrg0O1w8+ujf02Bv4BvLv0mf1r+J2LxnYdOUUqpsWi4O9avA24zxrTtbiERuajzAploNHmd2JnHHEPxVVfS9sK/2HHbbV3T83x5/OWkv3DohEP5zbu/4fx/nM/axrVJq1MppUaLREKkv3OLeyxjn0aWjdXBfjBws33O8SXAz0Tk4t4bMMbcY4yZa4yZ63Il9/rH3PPPJ+ecs6m/9z6annq6a3phWiG/+9zvuPmom9nSuoWzFp/FPR/dQyQeSWK1SimVXP2enZXIucUi8gNgP2PM90TkHODLxpizeq3nOqBttJ2d1RcTibD5oosILHuXyQ/cT9q8eT3m13fUc+PbN7J041Jm5s3k+sOvZ0bejCRVq5RSo/jsrATPLb4fqw9kLXApsMshhvcG4nZTevvteEpL2XrxDwlv2tRjfr4/n18f/WtuO+Y2agO1nLv4XO54/w5CsdBO6zLRKG2vv07trbcRqa0dqa+glFIjYsxesZ6I8KZNbDzrbJz5+ZQtfARnVtZOyzSHmrnp7Zt4Zv0z5HhzOH3K6XxlypcpWtdAy7NLaFm6lFh9PQDeypmUPfQQjvQR/2NBKZXiknUkoiHSj/a332bzgm+TPm8eE+++C3G7+1zuneq3+efzd+N+8S0OXRmjoAXiHjdZn/sc2V/6EohQ9V+XkHHUUZTeeQfidI7wN1FKpTINEdtoCxGApiefovrqq3GNH4/D47FuamUMxOMYE4e4wYTDxBoawOWkfvYknq1o5oVJzWTkFHLGlDM4c9qZ+J/5NzU/v57cr32N4v++GvtSGqWUGjQNEdtoDBGAxoWP0v7Wm4g4wOEAh1ivRbre+2fPJuv443Hm5BCLx3h92+s8vvpxXql6BWMMx0w8hgUvO/E89hzFP/sped/4RrK/llIqRWiI2EZriAxGdVs1j695nMfXPE5zsJFrF6cxc0Ub4353K3lfOCHZ5SmlUoCGiC0VQ6RTMBpkyYYlLPzgQb7+hzVMqoMPr/0qJ530QwrTCpNdnlJqL6YhYkvlEOlkjOGdlc9jLrqSeDDINd/0csDs4zmm9BgOmXAIeb68ZJeolNrLaIjYxkKIdAqtXcv6c86hJdvN1V+H7Q5rdJgZeTM4dPyhHDLhEA4sOhCfy5fkSpMj3t5O3R//SM455+Ip7T1cm1KqOw0R21gKEYD2N95g83cuwr///rSddjTv5jXxcmQFH9R9SDQexev0ckDRARw24TAOLzmcqTlTx8xZXdXXXkfTo4+SfthhTLz/viH/3uGtVRCL4pk8eUjXq1QyaIjYxlqIADT//e9U/881mHAYAGdODu5ZM2koy2N5YQcvpm3iPWNdNV+UVsQRJUdwRMkRHDz+YLI8O18AOVRMOEzzokW0v/EmRZddinvChGHbVm9tr77Glu98B+/UKYQ+XUvJ739H1he+MGTrjweDrDvxJExHBxVLnsWVp02Iau+mIWIbiyECEA+HCa1eTXD5cjqWLye4fAWhtWshZg077yibxKbzj+K5CXW8Wf0WrZFWnOJk/8L9OaLkCA4sPpCK7ApyfblDUkvzk09Sd++9RLdVg8OBKz+f0rv+iH/WrEGvvz+x5mbWn3oajowMyh97lI3nnEs8EKDi2cU4fEPTtFd3193suP12cDrJ+tJJlNx885CsV6lk0RCxjdUQ6Uu8o4PgJ58Q/PhjGhc+Snj9etKPOIL8Ky9ndVY7r1W9xmtVr7GqYVXXZ/J8eZRnl1ORXWE9cqzn4rTifpuD4h0dND3+OPX33U+0thb/nDkU/OD7uMeNY/N3v0usqZmS3/yazM99bli/97Yrr6R58bOULVyIf799aX/rbTZfcAEFF19M4cU/GPT6o3V1rDv+i6Qddii+adOo+8MfmXjvvWQcecQQVK9UcmiI2DRE+mYiERoffpgdd9xJvKODvK+dR8EPfoAzK4u6jjo+afiEdU3r2NC8gXVN61jfvJ6WcEvX531OHxMyJlCaWUpJRgklGSWUZpZSmlHKBGce4Seeof6BB4jV15M2bx4F3/9/pB1ySFfwRHfsYMv/+z7BlSspvvpn5H3ta/3WHKmtpfEvf8WZnU3eNy9EHP3feaDl+eep+uGPKPj+9yn80Q+7pm/98Y9pe/ElKp59dtCd7NXXXkfTk09S8cwi3BMmsOH0MzDhMBXPLMKRljaodauBMcYQ3rCBtldeIbTmU4ouuxRXfn6yy9qraIjYNER2L9rQwI7bf0vT44/jzMmh8JJLyDnzKzuNxRWPRtmxdQ1b17zHjg2raNtRRUdjHZGmRmhpxRuIktFhyAhCXiv4IrBxejYbvzyfrPkHU55VTnl2OcXpxTjE+uUfDwSouvwK2l58kbwLLqDoJ1f0OQZYeMsW6u+/n+annu7q58k84QQm3HgDDr9/19+tvp71p5yKa1wx5QsXIh5P17xIdTXrTvoSGUccQenvfzfg/Rf69FPWn3Y6ueedx7j/vhqAwLJlbPr6+eRdeCHFV1054HWrPRPv6KD9rbdof+VV2l55hcjWrdYMETKOPZbSO34/Zk4iGQoaIjYNkcQEV66k5oYb6Fj2Lt4ZM8g89lgi1dVEtm2zHjU1EOl1wywRHJmZOLOzITODcLqbQJqTZr/howNyWFbYwoamDbRGWrs+4nf5mZw1mZKMEsanj6fEP54Zf32D9L+9jO+4Y5j861u7giH06afU3XsvLc8uQRwOss84g/wF36L1hX9R++tf45s5k9I/3Il73Lidvo8xhqof/RdtL79M2ZNP4Js2badl6u66ix23/5ZJD9xP+mGHDWi/bb7oIjre/4B9/rkUV+5n/UfV111H02OPU/boQvz77Tegdav+GWNofuppWp57jsBbb2HCYcTvJ/2QQ8g4+igyjjySlueWUnvLLYy/8UZyzjg92SXvNTREbBoiiTPG0Prcc2y/5Rai1TW4CgtxT5iAu6TEfv7stSs/H0dmZr+jBxtjqA/Ws6F5AxtbNlrPzRupbq+mqq2KjmgHACe+E+eCF+JsLHHyyoklHPlOgH0+rCPmddFy0qG4zv0yxWUzKU4rxufy0frSS2y77HIc6emU3nkH/tmze2y3+Zln2HbFTyi6/DLyv/3tPmuLh0KsP/kUxOOh4m9P73JE5V1pe/11tiz4NkVXXEH+gm/1mBdrbWX9l07GmZtL+ROP7/G6R5vQhg14SktH3fdoXvws2y6/HM/kyWQcczTpRx1F2ty5OLzermVMLMamCy4g9MlqKhb9fUTPCtybaYjYNET2nInHMdEojm7NP8OyHWNoCjWxrW2bFSgv/ZuK2/6OKxwj4Hfyr/kenp4Tpi2tZxOE3+XH7/JTXu/kOw/Vkdka5bnzprDp4InWkU4wg8/97O9QVkrhn+6hKGPcLpsxWl98ia3f/z5FV15J/jcvTLz2WIwNX/4K8fZ2KpY82+e+an3hBbZe/EMKL72Ugou+s0f7ZjRp+Mtf2f7LX+KfexClv/3tqOlbiDY2sv5LJ+MuLaXskYd3+wdNeMsW1p92Ov7Zs5n0wP0J9aeNdRoitoGGyOqaVn6xeCX/ffJMZowbvmsnVE/BVavo+OADsk45FWdGOsFokO2B7dS013Q9N4WaCEaD1lFMYwvH3f0uJeua+fdxhSw5NovzHtjIjE0xrljgpCZPSHOlMTlrMmXZZUzOmkyWJwufy2eFkcNH4TX34Fr+KSy8A1/xeLxOLx6HB4/Tg9vhxuP04HK4etTZ9OSTVF/935TcditZJ564y++z9Yc/ou3f/6Zi0d/xlJUN894beg1//Svbf/FL/AceSHDFCpz5eUy88058M2cOyfqjjY20v/4fXPl5pB966B59dttVP6V58WLKn3wC3/Tp/S7f+Nhj1FxzLcVXX03e+V8faMkJi1RVseOOO8HpwFtejqesDE95uXVEN8x/oA0FDRHbQEOkqqmDw3/1ItedUsmFh5cPQ2VqqJhwmOrrr6f5iSfxTptGaM0a/Ff8kOoTD2Bjy0Y2Nm9kU8smNrZsZFvbNgw9/42Orzf85r4Yr84S/nhy33/NOsSBx+HB5/JRSCZX3bqFtjw/S396DFnebLLtR74vn/EZ4xmfPp5CfyHxHfWsP/lkfDNnMunBPyWtYzfw/vuYYHCPflE3PPww26//BRnHHUfpbbcSXPMpWy++mFhTExNuvGG34bkrJh4nuHw5ba+8SturrxD86GPrXjouF5Puu4/0Qw5OaD3t//kPm7+1gPzvfpeiH1+S2LaNYct3v0vg7Xcof+opvBXD8//aGEPzk0+y/cZfYYzB4fd33Y0UAKcTd2kJ3rJyvFOnkHv++biLi4ellsHQELENpjnr8F+9yP4Ts/nD1w4a4qrUUDPG0PDgg9TefAtpB89n0v19N1lE4hE6oh10RDoIxoJdRzTmD3/Gt/AfbLv1R7ROG084FiYSjxCOha1HPEwkFiEQDVDxxDscsHgND1w8lZUTYjSHm2kJtewUTi5xUZxezBc/cnDCoxtY8Z1jaPzCgcRNHIPBGIOJRvBVN5K+pZ70bU34gnE8UfBGBXfE4IrEcUXiOMNRnF4vmd+6gPTDDsPpcOISF06Hs+tst77EQyF23P5bGv70JzCGrJNOovjqn/XbJNX4yCPU/Pz6rgDp/Ms5WlfH1h/+iI733yf/e9+l8Ec/6rdpKNrYSPtrr9P26iu0v/oascZGEMG3335kHHkkaQfPp+b664nuqKNs4SN4y3f/yz3e0cH6U09DHA7KF/29R/9HfyK1tWw45VTckydT9vBfEZer/w/tgUhtLTXXXEvbyy+TNn8+42+4AU9pCbGWFsIbNxLesIHQhg2EN26yXq9fj8Prpejyy8g566xR1cymIWIbTIj8+NEPePXTOt65+jg9NXAvEVq/Hve4cXt8fUa8vZ11J56Eq6CA8Tf8L95p0/oOoe21rDvhBDKOPprS22/77PMmTmu4lfqOera1bxqRPDoAABuwSURBVKO6vZrqtmqq26vZ1lLFmb//iHE1Ie49wcG4Rpi4wzBxh6GkHlxxex1A2A1hV7fnzodbKGoyFDXD6zOFPx/noDHT+jcpCE5x4nV5yfXmkufLsy4SrXNwxH3LyNzSQPNJh2Lys8l+5Hlifg/rLziGTYdOpiMWJBANEIgEyPRkMj59PNP/vZHCO5/CddRhlP3uDty+nqdRx8Nhauwjv4xjj2XCzTfhzMjo+XPYsIG2F1+i7aWXCLz3HsTjOHNzST/iCDKOOpL0ww/vMTRMeMsWNp51Ns7sbMoWPoIzJ2eXP6vtt9xCw/0PMOnPD5I+f/4e/ZwBWpYsoerSyyi85L8o+N73drusicchHk8obFqWLKHm59cTDwYpuuxScr/+9X5DIbxpE9XXXkfgzTfxH3QQ46//Od599knoe8Samog1NeGeNGlYwkdDxDaYEHnk7c389KmPefGyo6kozOj/A2qv1vLcUqp+/GMwBmdeHmkHzyf9kENJP/QQ3BMnIiJsu/pqWhY9Q8WSZ/FMnJjwukPrN7Dh9NO7rnNxTZiAd+pUfNOm4p06Fe+0aXjKy4m6hLZIG23htp7PkTYC7c0UPvkq4576D3GXk81nH8aW4/clKoaYiRGMBmkINtAUaGDGPz/luKXbaffBH09y8P4U65dMSZ3he0tiTK+CDyqEv56cSUdBhnXGW7iVg96s56Ln4iybIvzmyw5wuShOK2Zc+jjczm5nZsUNB7xazTFPb6ChyM+iBTPICQhTljcx+eNasmusEaRbJxfQPHcqrfOmE5xaitPpQsQKPYc4uh5+l5+CNTvwXnoDnjn7U37/A32erNCxYoUVNid/nqZLzmNHxw4agg2ku9Mp8BeQ78+nwGc99+7H6q7q0sto+ec/KX/sUXyVlT3mGWMIrlxJyzOLaVmyhFhTE76ZM/HtPxv/7P3x7z8bd2npZxfONjay/Re/oGXJP/DNns2EX92It6Ii4X8bxhian/4b22+6CRMIkP/d75J/0Xf6/P6xlhZaX/gXLf/4B+1vvAHRKI60NLwzZ+KrrOx6ePepGPRRloaIbTAhsra2jc/f+m9u+sp+nD1v0hBXpkajSE0N7W+8SeDNN2h/402itbUAuCaMJ+2gubQsXmxdRHjlT/Z43cFPPsEEg3imTNnpL/c9Ed60iZpf/JL2117DO3Mm46+9Bv+cOVb9VVVsu/IqAsuWkfmFz1P8858TSHfSEGwgGo+S5k7DL16iTy6m4fbfAULRJZeQ+7XzaHriSWquvRbHEfOpu/qbVEfq2Na2jZr2GmoCNUTj0R51CMLkNc2c/uBa/AFrTLaoEz4t9/L+NBfvVBiqMsN79N2O/DjODxfHeXGOk6fOKCIvLZ9cby6hWIiGth18/85N5LTG+fF3nLT7d906IAi5vlzy/fnkefMQEYwxxIkTN3G8bREW3PwxHWlOHrpsNiX5ZUxvz2bKO9Vk/fsDzKat4HaTceSReCZOtMafW7ECEwwC4MzNxTd7P3zTptP0t6eJNTZRePEPyP/2twf8yztaV8f2G26kZckSPFP2Yfz1vyDtwAOItbXR9uKLtCz5B22vvw6RCO6SErJOPAFPWRnBVZ8QXLWK4KpVmA7rlHnxePBOn07WCV8kf8GCAdWjIWIbTIgYY5j7yxc4enoht541Z4grU6Nd59AZ7W++SeCNN2l/+23E7WafZxdbF1gmubbWpUvZfsONRHfsIOerX8W37yxqb74FjKH46qvJPuP03TbDRrZto/q662h/5VU8U/YhvHYdGUcfTcnvf7dHp3eHt2yh6fEn8FVWkn7E4T0CMm7ihGIhQtFQ1y/w7o+YiWGMoT3STmOwkYZQA/77nmbCU//hvbP3582jCmkINuB2ujn21VbmPbmSNZedhvO4Iyj0F1LoLyTfn097pJ26jrqdHjs6dtAUbAKskyNExDr6wUH5qka+fNdKPp2Vg6upjfIqKyRXTIL/zHKx+aASisZZg5CGY2Ei4Q4ytjZRsL6B4o0tTNjcRkFtiO1Fbv5yZj6bxzm7vlP37+Z3+cn0ZPZ4ZHmyyPRkku5O79GnZYwh9911VNz7Ap6GVlpmlJC5tgZHJEYwL53qgyuoOrichvJcYsR79ttFgqTVNJO3qZGCLa0UbWnDVE7h5FsW7uk/L0BDpMtgrxP53kPvsqK6mVd/cuwQVqX2RiYWs66f2YOO3OEWa2un7o47aHjoIYjF8B90EBNu+hWe0tKEPm+MoWXxYrbfcCP+OXMo+e3tw359UL81xeNUXfJjWp9/ntI77yTz2M9Z13mccirphx1G6Z13DFkfZfV119G08FG8M2fiPfHzNBw2k43+Nja22Gf0NW+kJdyC1+m1Tv12Wqd+d772R504vF6cThcOcfRopnOKExGhI9pBa7iVlnALbeE2WsOtXY+oifZZly9kOPuVOPtvMHxULrwx08G6UicOh3UyhVOcXSdX9K7L7XB3TZtbPJcL971wQPtGQ8Q22BB54LUNXL94JW/89FjGZ+96nCalkim4ejXBVavIPuWUfkcR6IuJRMDlGjUnkMQ7Otj09fMJbdhA2cN/pfbmW+j48EMqnl3c5zA3A2ViMaLbtyflKnZjDKFYaKez+oTPfgad/UedgTSSNERsgw2R5VXNnPz71/jtOXM4bY7eUlWpkRLZXsvGs84i3tZGvL2d4mv+h7zzzkt2WWNGskJk9JzkPERmjs8iw+vi7Q0NyS5FqTHFXVzExD/+AROP4z/gAHLPOSfZJaleROQEEVktImtF5Ko+5l8qIitF5CMR+ZeI9Hvv6IRCJIENe0XkUXv+WyJSZk//goi8KyIf28/D3lHhdAgHTc7lnY0aIkqNNF9lJfs8u5hJ9907qi7EUyAiTuBO4ESgEjhXRCp7LfY+MNcYMxt4Auj3lp/9/pQT3PACoNEYMwW4DbjJnl4HnGKM2Q+4AHiov+0NhfnleazZ3kZj+56drqiUGjz3hAk40ke8VUX1bz6w1hiz3hgTBhYCp3VfwBjzkjEmYL99E+j3jI9E/lTod8P2+wft108Ax4mIGGPeN8Zss6evAPwiMuynyswvt66s1aMRpdQY4hKRZd0eF/WaXwJs6fZ+qz1tVxYA/+h3owkU1teGe4+61rWMMSYqIs1APtaRSKevAO8ZY0K9N2B/2YsAPENwuuLs0mw8Lgdvb2jg+FlDd2aIUkqNYlFjzNyhWJGIfB2YCxzd37JDO5rZLojILKwmruP7mm+MuQe4B6yzswa7Pa/LyZyJOXokopRSn6kCuo/9U2pP60FEPg9cDRzd1x/9vSXSnJXIhruWEREXkA3U2+9LgaeBbxhj1iWwvSExvyyP5dtaaA/1fXGQUkqNMe8AU0WkXEQ8wDnAou4LiMgBwN3AqcaY2kRWmkiI9Lth+/0F9uszgReNMUZEcoBngauMMa8nUtBQmV+eRyxueG9z40huVimlRiVjTBS4GFgKrAIeM8asEJHrReRUe7FbgAzgcRH5QER6/67fSb/NWXYfR+eGncADnRsGlhljFgH3Aw+JyFqgAStosAueAlwjItfY045PNOEG48DJuTgE3t7QwJFTC4d7c0opNeoZY5YAS3pNu6bb68/v6TpT7or17k694zX8biePfnfPbuOplFJ7G71ifRjMK8vj/S1NhKKxZJeilFIpKaVDZH55HuFonI+3Nie7FKWUSkkpHSLzyqyLDt/ScbSUUmpYpHSI5KV7mFqUodeLKKXUMEnpEAGYV57HuxsbicVH1wkESimVClI+RA4uz6M1FGVVdUuyS1FKqZSTWiES3vnU4M5+Eb2/iFJKDb3UCZGty+D22bDpjR6TJ+T4Kc31a7+IUkoNg9QJkYKp4MuCxy+Etp4XxM8vy+PtDQ2MtgsrlVJqb5c6IeLLhrMegmAzPPEtiH028OL88jzq28Os2zE0V8IrpZSypE6IAIzbF06+DTa+Ci/9smvyPL1JlVJKDYvUChGAOefCQRfCa7fBJ9Y4YxUF6RRkeLRzXSmlhljqhQjACTfB+Dnw9PegYT0iwjy7X0QppdTQSc0QcfvgrD+DCDz2DYh0cPiUAqqaOvjeQ+9S1dSR7AqVUiolpGaIAOROhi/fAzUfw5LLOXveRK744nReXlPLcb95mTte/FRH91VKqUFK6fuJAPDiL+GVW+DUO+DA89naGOCXi1fx3IoayvLTuPbUWXxuetHQbU8ppZIgWfcTSf0QicfgL1+GzW/Cgn/C+P0BeGXNDq5btIL1de18obKYa06uZGJe2tBtVymlRpCGiG3IQwSgvQ7uOtJ6Pec8mHwYTJxPyJnG/a9t4Pf/WkvcGC48vIwTZo1j/9IcHA4Z2hqUUmoYaYjYhiVEAKregyVXwLb3wcRAnNZRyeTDqC+Yx69W5vDkynbiBvLTPRw9vZBjZxRx5NRCsv3uoa9HKaWGkIaIbdhCpFOoDba+DZv+Yz22LoNYCIBo4SzWZx/K0tAs/rSlmPogOB3C3Mm5HDujiHnleexTkEF2moaKUmp00RCxDXuI9BYJwrb3YOPrsOHfVt9JPILxZNBUfAjvOA/k4fqpvLzjs59NfrqHisJ0KgoyqChMp7wgnYrCDEpy/Pg9zp23EYtYTWoZReDoY75SSg2ShohtxEOkt1ArbHgV1r4Aa5+Hps0ARHMqqMucQX0snZpIGluCXta3edga8tFkMmgmnVxameppYJq3njJnHSXsoChWQ1a4Fgdxoq40QvmVMH4O3kkH4io5AAqmgdOVvO+rlEoJGiK2pIdId8ZA/TorUNb9y3rd0QjBJjDx3X60wZFPlRSxKZbP+mgBO0wOFVLNvo4NzJJNpInVhBbEwxb3PmxPm0LYl0/cl4vx5+FIy8OZUYA7Mx9vZgFpmXlk+t1k+dxk+Fw4x0LHf3s9VL8PxftC5rihXbcxULvSOntv3H7WhalK7cU0RGyjKkR2JR6HULMVKB2NELCDxZdjXeSYPdG6at4WjMTY0Rqiri1kPbcGiNauxV/3EbnNKxkfWE1JZBNZtOGg759Hu/Gy1pTwqSlldbyUzc5J1HjLCfjGkel3k+514XU58LqdpDlj5JkW8k0jOaaJ7HgTXonhcDhxOh24XC6cTmfXw+V04iGCx4TwmBDueBB3PIQrHsIZC+IUg2RPxJFXhuRVQG4ZpBcM/S/ejiarn2rDK9YgmtuXfzav5CCYfhLM+BIUzhj4tneshuVPwvKnoP5Ta1peBcw6w3oU77t3B4oxULfGapbNKLYGJc0qGf3fKR63/g+110Gk3foZu/3JrmqvoiFi2ytCZLjEYxBsJtSyg0DzDkItOwi31BFrr0daqvA1rSGrZS1p4bquj3RIGlXuSQSMl+x4I7mxRrJoHXQpEeOkAw8hPAAUSnOP+QF8VEkR1TKeVkcWfgnjJ4SfIH5C+EwQHyG8JkgcJ+3OLALOLNpdOXQ4swi4sgm6swm6shgf2kBF2/uMC6y2mv0cXmqy51CTN4/GnH0pbFnOxNqXyW+2QqUtbSLV44+lZvxxNBYciMPhRBAcAiKCCDhEEMDhgLS2zRRvWULRpiWkN32CQWgddwiNFafgcDrJXb+Y9G3/QUyMSO4+hKafTnTG6UjxzJ2O+AQgFoZgMxJqxRGP4JA4Eo/hII7DRBETh3gUxGEdQWWVgMs76J/JLrXXw/qXrMe6l6Clqud8f651tDVutvVcvK/VjGpiEOmw7ggaCViPsP0cDVnBIw7rQedrsR7+PPsXva/PknZiDDRvgS1vQ9W70LINAvVWaATqINBg1dPJ6YEJB8CkQ+1T8g8Gf86Q7bIe4jHrj8H2HVY98agduvLZPuh87XBZf0BljAPP6LquTEPENqZDJFGBBtjxCdSu+uw5FrY67jOKIb3Ifl0E6UWY9ALC4iYSiRGJRu2H9TociRGORgnjocO46cBD0HgIxh2EojFCkTihaJx4OEBaoIr0wFayOqxHTmgbueFtpEWbCYmPkMNHEB9B8RLERwAvHXhxmCiZ8VYy4y1kmVayTAuZtOPEahIM4+JDM5U34rN4LTqTD8wUwux8BlwxDXze+R5fcLzLoY4VeCVKm/HRQhpBYwVesLN+3ATxMEHq2d+xHoBl8Wk8EzuUJbH57CC3x7rzaOFE59t8yfEmhzhW4RDD6ngpNSaPTAmQRYAsCZBJAL+E9/hHVmtyqCafagqoNgVUU0Ab6eQ6WsmnlTxpJZcW8mghhxZyTAsCNEkWjZJNI589N5BNExlUmK0cwodMi6/HgaFV0vnYPYePvAfyiW822fFWJkfXMTmynsmRdUyKbMTDnte+KzEcbPdMZJt3H7b5plDjn0KNbwoBTwESDzMusJpJ7cuZ3LGCio4V5MTqAQiJlwZnIa3ObNqdObS7cmh35dLhzqHDnYtxeigNrKKs/UNKAp/gJEYcYbuvnI3p+1Pj2wePxPCZMF77DxWvfRTtMSEcJorBQRzBiJM4Dow4iNvT3LF2/JEm0sIN+CON+CJNONh983RfQq4MOrxFBLwFdHgLCXgLCbsy8ETb8ERarEe0FW+kBW+kGU+0BTHQ4ckl4Mmnw5NHhzuPgDuPDk8+AU8eWSXTOeywowf08xjVISIiJwC/BZzAfcaYX/Wa7wX+DBwE1ANnG2M22vN+CiwAYsCPjDFLd7ctDZExorP5oqMRMsd3/VVnjCEaN0RicSIx6zkeN8QNxI0hFjcYAybUinfTi/i2vYVEAkg0iEQ77Gfr4YgFibnSaSw7kYbJJ9GRNqHHeuLGEI0ZonFrW53PzkAtpdv+ycTt/8IV6yDsyiTkyiTsSu/2OoOwM4OouLGPQYjhJIbYzw6Ix8gI7yArVENmeDtZoe1khWvIDtfgjoe6dkVUXASc2bS7cmhz5tDmzKbVkU0cISvWREb3R/SzX3gxnGzyV7IybS7LfXNZ555COO7o+h69W0YdJsb42FbKIusZH6sigouQ+OjA2xX8QbwExUcYN4IBjNXEauIIBsHgJEZWrIny6HrKYhvZJ7aBYrOjazuNZJFOAA/WjeGqpZhVrpms9sxgjXsWWz3lRHEQtX++0bghGvvsZxCNma7WN68Js69ZwwF8whyzitlmNWkEe3yvDuOhA4/1PYyHKE4cdow47ehwyGfvA8ZLPdnUmyzqTRZ1ZFFvrPcNZBI1TgQQMfY+oOu7u4mRTwvF0kiRNFIkTRRLI8XSSCFNeCVKyLhpJp1mk77TM0CBNFNAC/nSTIE0kydtXd/l3czPcdBlfxvQf6lRGyIi4gTWAF8AtgLvAOcaY1Z2W+b7wGxjzPdE5BzgDGPM2SJSCTwCzAcmAC8A04wxuxz5UENEpTxjPjtBIy0fvFmJ91l07zvIHGfdEno06GiE7Svsx3LrTqMTD4bS+ZBZPHTbiUWhtdrqL3H7weXHiBCLGyIxQzgWJxY3OEUQR7dmTbuZs7Ops7vee95g/aFhjPWjihvz2bR49+Ws351dv0KNwcRCiMtnbatzzZ2tYp3bs2vqLENiUaSjHmnfgbh9eMbNGNCuGc0hcihwnTHmi/b7nwIYY27stsxSe5k3RMQF1ACFwFXdl+2+3K62pyGilFJ7LlkhkshQ8CXAlm7vt9rT+lzGGBMFmoH8BD+LiFwkIstEZFk0Gu09Wyml1Cg1Ku4nYoy5xxgz1xgz1+XSC++UUmpvkUiIVAETu70vtaf1uYzdnJWN1cGeyGeVUkrtpRIJkXeAqSJSLiIe4BxgUa9lFgEX2K/PBF40VmfLIuAcEfGKSDkwFXh7aEpXSimVbP22HRljoiJyMbAU6xTfB4wxK0TkemCZMWYRcD/wkIisBRqwggZ7uceAlUAU+MHuzsxSSim1d9GLDZVSKgUkcnbWYK7525VR0bGulFJqeNnX/N0JnAhUAufa1/J1twBoNMZMAW4DbupvvRoiSik1NswH1hpj1htjwsBC4LRey5wGPGi/fgI4TmT3V8KOuvNpA4GAEZGOQazCBYzWi020toHR2gZGaxuYvbU2v4gs6/b+HmPMPd3e93Xd3sG91tHjmj8R6bzmr45dGHUhYowZ1NGRiCwzxswdqnqGktY2MFrbwGhtA6O17RltzlJKqbFhMNf87ZKGiFJKjQ2DueZvl0Zdc9YQuKf/RZJGaxsYrW1gtLaBScnaBnPN3+6MuutElFJK7T20OUsppdSAaYgopZQasJQJERE5QURWi8haEbkq2fV0JyIbReRjEfmg13ncyajlARGpFZHl3ablicjzIvKp/Zy7u3WMcG3XiUiVve8+EJGTklTbRBF5SURWisgKEfkve3rS991uakv6vhMRn4i8LSIf2rX93J5eLiJv2f9fH7U7ekdLbX8SkQ3d9tucka6tW41OEXlfRBbb75O+33ZijNnrH1idROuACsADfAhUJruubvVtBAqSXYddy1HAgcDybtNuBq6yX18F3DSKarsOuHwU7LfxwIH260ysW0ZXjoZ9t5vakr7vsO4Km2G/dgNvAYcAjwHn2NPvAv7fKKrtT8CZyf43Z9d1KfAwsNh+n/T91vuRKkciiVzOrwBjzCtYZ110132ogweB00e0KNsuahsVjDHVxpj37NetwCqsq3uTvu92U1vSGUub/dZtPwxwLNawGpC8/bar2kYFESkFvgTcZ78XRsF+6y1VQiSh2/AmkQH+KSLvishFyS6mD8XGmGr7dQ1QnMxi+nCxiHxkN3clpamtOxEpAw7A+st1VO27XrXBKNh3dpPMB0At8DxWq0GTsW6lDUn8/9q7NmNM5377X3u/3WaPbJsMtwM/AeL2+3xGyX7rLlVCZLQ7whhzINbomT8QkaOSXdCuGOs4edT8NQb8EdgHmANUA79JZjEikgE8CVxijGnpPi/Z+66P2kbFvjPGxIwxc7CukJ4PzEhGHX3pXZuI7Av8FKvGeUAecOVI1yUiJwO1xph3R3rbeypVQmRU34bXGFNlP9cCT2P9RxpNtovIeAD7uTbJ9XQxxmy3/6PHgXtJ4r4TETfWL+m/GmOesiePin3XV22jad/Z9TQBLwGHAjn2sBowCv6/dqvtBLt50BhjQsD/kZz9djhwqohsxGqePxbrPiCjar9B6oRIIpfzJ4WIpItIZudr4Hhg+e4/NeK6D3VwAfD3JNbSQ+cvaNsZJGnf2e3R9wOrjDG3dpuV9H23q9pGw74TkUIRybFf+4EvYPXZvIQ1rAYkb7/1Vdsn3f4oEKw+hxHfb8aYnxpjSo0xZVi/z140xnyNUbDfdpLsnv2hegAnYZ2Vsg64Otn1dKurAutssQ+BFcmuDXgEq2kjgtWmugCrrfVfwKfAC0DeKKrtIeBj4COsX9jjk1TbEVhNVR8BH9iPk0bDvttNbUnfd8Bs4H27huXANfb0CuBtYC3wOOAdRbW9aO+35cBfsM/gStYDOIbPzs5K+n7r/dBhT5RSSg1YqjRnKaWUSgINEaWUUgOmIaKUUmrANESUUkoNmIaIUkqpAdMQUUopNWAaIkoppQbs/wOxtPSMe3oDWwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test_scale, verbose=0)\n",
    "np.savetxt(save+str(count)+'_Score_'+name+'.txt', score)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(score)\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'],label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],label='val_loss')\n",
    "loss_ax.plot(hist.history['mae'],label='train acc')\n",
    "loss_ax.plot(hist.history['val_mae'],label='val acc')\n",
    "plt.savefig(save+str(count)+'_Train_curve_'+name+'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "real:\n",
      "[170. 170. 250. 190.]\n",
      "pred:\n",
      "[177, 161, 249, 196]\n",
      " \n",
      "1\n",
      "real:\n",
      "[220. 140. 160. 180.]\n",
      "pred:\n",
      "[218, 135, 151, 178]\n",
      " \n",
      "2\n",
      "real:\n",
      "[ 60. 150.  20. 210.]\n",
      "pred:\n",
      "[40, 142, 71, 166]\n",
      " \n",
      "3\n",
      "real:\n",
      "[ 40. 180.  50.  60.]\n",
      "pred:\n",
      "[47, 175, 45, 70]\n",
      " \n",
      "4\n",
      "real:\n",
      "[ 60.  30. 150. 180.]\n",
      "pred:\n",
      "[60, 39, 146, 188]\n",
      " \n",
      "5\n",
      "real:\n",
      "[270. 270.  10.  30.]\n",
      "pred:\n",
      "[259, 253, 11, 30]\n",
      " \n",
      "6\n",
      "real:\n",
      "[ 70.  90. 210.  50.]\n",
      "pred:\n",
      "[66, 89, 216, 38]\n",
      " \n",
      "7\n",
      "real:\n",
      "[ 70. 180. 200. 170.]\n",
      "pred:\n",
      "[68, 175, 192, 171]\n",
      " \n",
      "8\n",
      "real:\n",
      "[ 20.  90. 210. 260.]\n",
      "pred:\n",
      "[14, 95, 206, 260]\n",
      " \n",
      "9\n",
      "real:\n",
      "[ 50. 250.  60. 150.]\n",
      "pred:\n",
      "[50, 241, 58, 152]\n",
      " \n",
      "10\n",
      "real:\n",
      "[270.  20. 110. 200.]\n",
      "pred:\n",
      "[265, 12, 109, 212]\n",
      " \n",
      "11\n",
      "real:\n",
      "[120. 180.  50. 240.]\n",
      "pred:\n",
      "[125, 168, 59, 240]\n",
      " \n",
      "12\n",
      "real:\n",
      "[150.  40.  10.  90.]\n",
      "pred:\n",
      "[144, 26, 12, 110]\n",
      " \n",
      "13\n",
      "real:\n",
      "[290. 220.  80. 210.]\n",
      "pred:\n",
      "[296, 212, 76, 208]\n",
      " \n",
      "14\n",
      "real:\n",
      "[150. 160. 100.  20.]\n",
      "pred:\n",
      "[158, 171, 94, 25]\n",
      " \n",
      "15\n",
      "real:\n",
      "[180. 170. 240. 190.]\n",
      "pred:\n",
      "[179, 167, 230, 196]\n",
      " \n",
      "16\n",
      "real:\n",
      "[180. 190.  20. 190.]\n",
      "pred:\n",
      "[181, 162, 26, 198]\n",
      " \n",
      "17\n",
      "real:\n",
      "[160. 180. 130. 170.]\n",
      "pred:\n",
      "[160, 170, 128, 173]\n",
      " \n",
      "18\n",
      "real:\n",
      "[240. 140. 270.  20.]\n",
      "pred:\n",
      "[239, 144, 272, 14]\n",
      " \n",
      "19\n",
      "real:\n",
      "[ 60. 280.  40. 260.]\n",
      "pred:\n",
      "[60, 270, 47, 270]\n",
      " \n",
      "20\n",
      "real:\n",
      "[110.  10. 170.  50.]\n",
      "pred:\n",
      "[103, 11, 162, 69]\n",
      " \n",
      "21\n",
      "real:\n",
      "[130.  30. 210.  50.]\n",
      "pred:\n",
      "[125, 19, 218, 52]\n",
      " \n",
      "22\n",
      "real:\n",
      "[ 20.  30.  70. 290.]\n",
      "pred:\n",
      "[10, 35, 71, 310]\n",
      " \n",
      "23\n",
      "real:\n",
      "[230. 110.  40.  90.]\n",
      "pred:\n",
      "[220, 92, 45, 80]\n",
      " \n",
      "24\n",
      "real:\n",
      "[110.  60.  40.  40.]\n",
      "pred:\n",
      "[110, 57, 42, 37]\n",
      " \n",
      "25\n",
      "real:\n",
      "[240. 230. 280. 200.]\n",
      "pred:\n",
      "[246, 221, 290, 206]\n",
      " \n",
      "26\n",
      "real:\n",
      "[ 60. 180. 280. 150.]\n",
      "pred:\n",
      "[58, 178, 275, 146]\n",
      " \n",
      "27\n",
      "real:\n",
      "[230.  30. 130.  40.]\n",
      "pred:\n",
      "[232, 29, 124, 56]\n",
      " \n",
      "28\n",
      "real:\n",
      "[ 60. 150. 220. 150.]\n",
      "pred:\n",
      "[52, 148, 226, 139]\n",
      " \n",
      "29\n",
      "real:\n",
      "[280. 110. 180. 290.]\n",
      "pred:\n",
      "[289, 108, 190, 292]\n",
      " \n",
      "30\n",
      "real:\n",
      "[110. 270. 180. 300.]\n",
      "pred:\n",
      "[112, 254, 185, 310]\n",
      " \n",
      "31\n",
      "real:\n",
      "[150. 280. 140.  60.]\n",
      "pred:\n",
      "[140, 279, 141, 54]\n",
      " \n",
      "32\n",
      "real:\n",
      "[ 80. 160. 220.  10.]\n",
      "pred:\n",
      "[80, 159, 219, 12]\n",
      " \n",
      "33\n",
      "real:\n",
      "[190. 200. 290. 170.]\n",
      "pred:\n",
      "[187, 189, 294, 168]\n",
      " \n",
      "34\n",
      "real:\n",
      "[70. 50. 40. 70.]\n",
      "pred:\n",
      "[70, 52, 51, 62]\n",
      " \n",
      "35\n",
      "real:\n",
      "[ 10. 190. 190. 210.]\n",
      "pred:\n",
      "[13, 175, 193, 207]\n",
      " \n",
      "36\n",
      "real:\n",
      "[180. 220. 180.  50.]\n",
      "pred:\n",
      "[187, 215, 183, 42]\n",
      " \n",
      "37\n",
      "real:\n",
      "[200. 180.  80.  70.]\n",
      "pred:\n",
      "[197, 165, 77, 70]\n",
      " \n",
      "38\n",
      "real:\n",
      "[250. 280.  70. 240.]\n",
      "pred:\n",
      "[248, 266, 70, 252]\n",
      " \n",
      "39\n",
      "real:\n",
      "[170. 230. 270.  80.]\n",
      "pred:\n",
      "[156, 252, 279, 77]\n",
      " \n",
      "40\n",
      "real:\n",
      "[220. 160. 290. 230.]\n",
      "pred:\n",
      "[228, 170, 282, 227]\n",
      " \n",
      "41\n",
      "real:\n",
      "[260. 290. 230. 170.]\n",
      "pred:\n",
      "[269, 283, 229, 169]\n",
      " \n",
      "42\n",
      "real:\n",
      "[180. 240. 100.  40.]\n",
      "pred:\n",
      "[182, 252, 89, 56]\n",
      " \n",
      "43\n",
      "real:\n",
      "[130. 230. 160. 170.]\n",
      "pred:\n",
      "[131, 225, 154, 179]\n",
      " \n",
      "44\n",
      "real:\n",
      "[ 40.  90.  30. 210.]\n",
      "pred:\n",
      "[38, 76, 53, 186]\n",
      " \n",
      "45\n",
      "real:\n",
      "[120.  30.  10. 220.]\n",
      "pred:\n",
      "[99, 176, 31, 85]\n",
      " \n",
      "46\n",
      "real:\n",
      "[ 80.  40. 290. 120.]\n",
      "pred:\n",
      "[68, 37, 298, 118]\n",
      " \n",
      "47\n",
      "real:\n",
      "[280.  20. 130. 130.]\n",
      "pred:\n",
      "[248, 33, 146, 127]\n",
      " \n",
      "48\n",
      "real:\n",
      "[ 80. 280. 280. 180.]\n",
      "pred:\n",
      "[81, 268, 287, 162]\n",
      " \n",
      "49\n",
      "real:\n",
      "[210. 220. 280. 120.]\n",
      "pred:\n",
      "[212, 214, 287, 117]\n",
      " \n",
      "50\n",
      "real:\n",
      "[270. 240. 170. 130.]\n",
      "pred:\n",
      "[265, 245, 162, 132]\n",
      " \n",
      "51\n",
      "real:\n",
      "[100.  60. 150.  90.]\n",
      "pred:\n",
      "[101, 73, 148, 93]\n",
      " \n",
      "52\n",
      "real:\n",
      "[150. 200. 100.  80.]\n",
      "pred:\n",
      "[147, 196, 96, 76]\n",
      " \n",
      "53\n",
      "real:\n",
      "[ 60. 260. 270. 220.]\n",
      "pred:\n",
      "[48, 260, 264, 227]\n",
      " \n",
      "54\n",
      "real:\n",
      "[ 40.  30.  50. 240.]\n",
      "pred:\n",
      "[91, 163, 25, 85]\n",
      " \n",
      "55\n",
      "real:\n",
      "[130.  40. 290. 130.]\n",
      "pred:\n",
      "[120, 72, 263, 127]\n",
      " \n",
      "56\n",
      "real:\n",
      "[170. 120. 240. 210.]\n",
      "pred:\n",
      "[169, 117, 228, 213]\n",
      " \n",
      "57\n",
      "real:\n",
      "[230.  30.  10.  60.]\n",
      "pred:\n",
      "[210, 21, 22, 60]\n",
      " \n",
      "58\n",
      "real:\n",
      "[ 60. 100. 190. 200.]\n",
      "pred:\n",
      "[63, 104, 205, 144]\n",
      " \n",
      "59\n",
      "real:\n",
      "[130.  80.  80. 270.]\n",
      "pred:\n",
      "[131, 76, 64, 271]\n",
      " \n",
      "60\n",
      "real:\n",
      "[120. 250. 230.  80.]\n",
      "pred:\n",
      "[122, 246, 226, 74]\n",
      " \n",
      "61\n",
      "real:\n",
      "[200. 260. 180. 170.]\n",
      "pred:\n",
      "[198, 264, 184, 160]\n",
      " \n",
      "62\n",
      "real:\n",
      "[120. 170. 280. 200.]\n",
      "pred:\n",
      "[126, 161, 282, 201]\n",
      " \n",
      "63\n",
      "real:\n",
      "[100. 190. 300.  80.]\n",
      "pred:\n",
      "[97, 173, 307, 76]\n",
      " \n",
      "64\n",
      "real:\n",
      "[80. 40. 30. 10.]\n",
      "pred:\n",
      "[109, 21, 29, 15]\n",
      " \n",
      "65\n",
      "real:\n",
      "[120. 210. 260.  20.]\n",
      "pred:\n",
      "[116, 199, 261, 22]\n",
      " \n",
      "66\n",
      "real:\n",
      "[ 20. 200. 270. 290.]\n",
      "pred:\n",
      "[16, 206, 261, 297]\n",
      " \n",
      "67\n",
      "real:\n",
      "[ 40. 160. 140.  30.]\n",
      "pred:\n",
      "[36, 142, 137, 35]\n",
      " \n",
      "68\n",
      "real:\n",
      "[ 60. 180. 240. 200.]\n",
      "pred:\n",
      "[58, 183, 236, 198]\n",
      " \n",
      "69\n",
      "real:\n",
      "[ 50.  80. 260.  60.]\n",
      "pred:\n",
      "[56, 66, 265, 57]\n",
      " \n",
      "70\n",
      "real:\n",
      "[270. 300. 100. 160.]\n",
      "pred:\n",
      "[278, 290, 99, 173]\n",
      " \n",
      "71\n",
      "real:\n",
      "[210. 300.  70. 120.]\n",
      "pred:\n",
      "[214, 285, 67, 125]\n",
      " \n",
      "72\n",
      "real:\n",
      "[280. 260.  60. 160.]\n",
      "pred:\n",
      "[277, 255, 72, 167]\n",
      " \n",
      "73\n",
      "real:\n",
      "[170. 280.  70. 170.]\n",
      "pred:\n",
      "[172, 277, 67, 174]\n",
      " \n",
      "74\n",
      "real:\n",
      "[160. 210.  50. 250.]\n",
      "pred:\n",
      "[161, 196, 55, 244]\n",
      " \n",
      "75\n",
      "real:\n",
      "[120. 220.  40.  40.]\n",
      "pred:\n",
      "[130, 216, 54, 42]\n",
      " \n",
      "76\n",
      "real:\n",
      "[140. 130. 280.  20.]\n",
      "pred:\n",
      "[142, 137, 297, 10]\n",
      " \n",
      "77\n",
      "real:\n",
      "[260. 130. 100. 270.]\n",
      "pred:\n",
      "[261, 123, 98, 262]\n",
      " \n",
      "78\n",
      "real:\n",
      "[130. 270. 150. 120.]\n",
      "pred:\n",
      "[119, 262, 152, 137]\n",
      " \n",
      "79\n",
      "real:\n",
      "[180.  60. 300.  90.]\n",
      "pred:\n",
      "[180, 50, 303, 103]\n",
      " \n",
      "80\n",
      "real:\n",
      "[180. 190.  70. 270.]\n",
      "pred:\n",
      "[193, 174, 69, 261]\n",
      " \n",
      "81\n",
      "real:\n",
      "[140.  70. 220. 290.]\n",
      "pred:\n",
      "[139, 64, 210, 297]\n",
      " \n",
      "82\n",
      "real:\n",
      "[300.  40. 130. 150.]\n",
      "pred:\n",
      "[275, 61, 134, 145]\n",
      " \n",
      "83\n",
      "real:\n",
      "[110. 250. 150.  40.]\n",
      "pred:\n",
      "[109, 255, 154, 37]\n",
      " \n",
      "84\n",
      "real:\n",
      "[ 10. 120. 240. 300.]\n",
      "pred:\n",
      "[15, 137, 227, 302]\n",
      " \n",
      "85\n",
      "real:\n",
      "[210. 110. 100. 270.]\n",
      "pred:\n",
      "[206, 111, 99, 272]\n",
      " \n",
      "86\n",
      "real:\n",
      "[100. 200. 190. 150.]\n",
      "pred:\n",
      "[107, 198, 178, 153]\n",
      " \n",
      "87\n",
      "real:\n",
      "[ 60. 210.  90. 250.]\n",
      "pred:\n",
      "[54, 210, 88, 257]\n",
      " \n",
      "88\n",
      "real:\n",
      "[ 40. 210. 220. 120.]\n",
      "pred:\n",
      "[32, 216, 231, 119]\n",
      " \n",
      "89\n",
      "real:\n",
      "[120.  20. 190. 230.]\n",
      "pred:\n",
      "[109, 21, 189, 234]\n",
      " \n",
      "90\n",
      "real:\n",
      "[ 40. 210. 140. 240.]\n",
      "pred:\n",
      "[34, 214, 138, 244]\n",
      " \n",
      "91\n",
      "real:\n",
      "[ 10. 300. 230. 110.]\n",
      "pred:\n",
      "[14, 291, 241, 110]\n",
      " \n",
      "92\n",
      "real:\n",
      "[240.  10. 220. 230.]\n",
      "pred:\n",
      "[226, 10, 218, 234]\n",
      " \n",
      "93\n",
      "real:\n",
      "[ 60. 130. 200. 240.]\n",
      "pred:\n",
      "[49, 122, 203, 246]\n",
      " \n",
      "94\n",
      "real:\n",
      "[ 10. 120.  80. 180.]\n",
      "pred:\n",
      "[10, 125, 78, 168]\n",
      " \n",
      "95\n",
      "real:\n",
      "[130.  90. 260. 180.]\n",
      "pred:\n",
      "[125, 104, 258, 178]\n",
      " \n",
      "96\n",
      "real:\n",
      "[170. 150.  70. 250.]\n",
      "pred:\n",
      "[176, 139, 62, 249]\n",
      " \n",
      "97\n",
      "real:\n",
      "[130. 260. 130. 270.]\n",
      "pred:\n",
      "[136, 257, 128, 265]\n",
      " \n",
      "98\n",
      "real:\n",
      "[ 20.  50. 150.  30.]\n",
      "pred:\n",
      "[12, 67, 135, 26]\n",
      " \n",
      "99\n",
      "real:\n",
      "[120.  80. 100.  40.]\n",
      "pred:\n",
      "[122, 70, 102, 51]\n",
      " \n",
      "final mean_absolute_error: 8.5375\n"
     ]
    }
   ],
   "source": [
    "Y_hat_test = abs(model.predict(X_test,batch_size=32))\n",
    "Y_hat_test_inverse = sc.inverse_transform(Y_hat_test)\n",
    "Y_test_inverse = sc.inverse_transform(Y_test_scale)\n",
    "\n",
    "record_pred = []\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "  Y_hat= list(map(int, Y_hat_test_inverse[i]))\n",
    "  print(i,'real:',Y_test_inverse[i],'pred:',Y_hat,' ',sep='\\n')\n",
    "  Y_append= np.append(Y_test_inverse[i],Y_hat)\n",
    "  record_pred.append(Y_append)  \n",
    "\n",
    "np.savetxt(save+str(count)+'_Record pred_'+name+'.csv', record_pred,delimiter=',')\n",
    "model.save_weights(save+str(count)+\"_Weight_\"+name+\".h5\")\n",
    "\n",
    "record_mae = []\n",
    "pred_shape = np.shape(record_pred)\n",
    "for i in range(pred_shape[0]):\n",
    "    record_mae.append(MAE(record_pred[i][0:4],record_pred[i][4:]))\n",
    "\n",
    "final_metric = np.mean(record_mae)\n",
    "\n",
    "print('final mean_absolute_error:',final_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\", \"w\") as json_file : \n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "from keras.models import model_from_json \n",
    "\n",
    "json_file = open(\"model.json\", \"r\") \n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close() \n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "loaded_model.load_weights(\"model.h5\") \n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "loaded_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['mae'])\n",
    "\n",
    "# model evaluation\n",
    "\n",
    "score = loaded_model.evaluate(X_test_scale,Y_test_scale,verbose=0)\n",
    "print(\"%s : %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
